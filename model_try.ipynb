{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a98ee283",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: seaborn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 2)) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (3.10.1)\n",
            "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (2.7.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (2025.3.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (78.1.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7c7edcbd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.2.5)\n",
            "Requirement already satisfied: scipy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.15.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "12023248",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "82b9c411",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, f_classif, SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "200f1aad",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./datasets/train/train.csv\") # для train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "20827f62",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              " 0             0.5        0.5        1.0        1.0        0.0        0.0   \n",
              " 1             0.5        0.5        1.0        1.0        0.0        0.0   \n",
              " 2             0.5        0.5        1.0        1.0        1.0        3.0   \n",
              " 3             0.5        0.5        1.0        1.0        1.0        3.0   \n",
              " 4             0.5        0.5        1.0        1.0        1.0        9.0   \n",
              " ...           ...        ...        ...        ...        ...        ...   \n",
              " 247967        0.5        0.5        1.0        1.0        0.0        1.0   \n",
              " 247968        0.5        0.5        1.0        1.0        1.0        2.0   \n",
              " 247969        0.5        0.5        1.0        1.0        1.0        4.0   \n",
              " 247970        0.5        0.5        1.0        1.0        0.0        1.0   \n",
              " 247971        0.5        0.5        1.0        1.0        0.0        4.0   \n",
              " \n",
              "         feature_6  feature_7  feature_8  feature_9  ...  feature_1357  \\\n",
              " 0             0.0        0.0        1.0        1.0  ...           0.0   \n",
              " 1             0.0        1.0        0.0        1.0  ...          -1.0   \n",
              " 2             1.0        4.0        0.0        9.0  ...           0.0   \n",
              " 3             1.0        0.0        3.0        8.0  ...           0.0   \n",
              " 4             1.0        1.0        3.0       15.0  ...           0.0   \n",
              " ...           ...        ...        ...        ...  ...           ...   \n",
              " 247967        1.0        0.0        3.0        5.0  ...           0.0   \n",
              " 247968        3.0        1.0        0.0        7.0  ...           0.0   \n",
              " 247969        1.0        5.0        0.0       11.0  ...           0.0   \n",
              " 247970        1.0        0.0        1.0        3.0  ...           0.0   \n",
              " 247971        3.0        0.0        3.0       10.0  ...           0.0   \n",
              " \n",
              "         feature_1358  feature_1359  feature_1360  feature_1361  feature_1362  \\\n",
              " 0                0.0           0.0             1             1             1   \n",
              " 1               -1.0          -1.0             1             1             1   \n",
              " 2                0.0           0.0             0             0             0   \n",
              " 3                0.0           0.0             0             0             0   \n",
              " 4                0.0           0.0             0             0             0   \n",
              " ...              ...           ...           ...           ...           ...   \n",
              " 247967           0.0           0.0             0             0             0   \n",
              " 247968           0.0           0.0             0             0             0   \n",
              " 247969           0.0           0.0             0             0             0   \n",
              " 247970           0.0           0.0             0             0             0   \n",
              " 247971           0.0           0.0             0             0             0   \n",
              " \n",
              "         feature_1363  feature_1364  feature_1365  feature_1366  \n",
              " 0                  1             1             1             0  \n",
              " 1                  1             0             0             1  \n",
              " 2                  0             0             0             0  \n",
              " 3                  0             0             0             0  \n",
              " 4                  0             0             0             0  \n",
              " ...              ...           ...           ...           ...  \n",
              " 247967             0             0             1             0  \n",
              " 247968             0             0             0             0  \n",
              " 247969             0             0             0             0  \n",
              " 247970             0             0             0             0  \n",
              " 247971             0             0             0             0  \n",
              " \n",
              " [247972 rows x 1367 columns],\n",
              " 0         0.0\n",
              " 1         0.0\n",
              " 2         0.0\n",
              " 3         0.0\n",
              " 4         1.0\n",
              "          ... \n",
              " 247967    0.0\n",
              " 247968    0.0\n",
              " 247969    0.0\n",
              " 247970    0.0\n",
              " 247971    0.0\n",
              " Name: target, Length: 247972, dtype: float64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Удаляем индекс, так как он не несёт информации для модели\n",
        "X = df.drop(['index', 'target'], axis=1)  # Все фичи (feature_1 ... feature_1357)\n",
        "y = df['target']  # Целевая переменная\n",
        "\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e6fb7e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "indexes = df['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "97608bd4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходное число признаков: 1367\n",
            "Число признаков после отбора: 200\n"
          ]
        }
      ],
      "source": [
        "# 1. Отбор признаков: удаляем низковариативные (константные и почти константные)\n",
        "# Сделаем pipeline для более эффективного отбора признаков(их сокращения)\n",
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('kbest', SelectKBest(f_classif, k=200)),\n",
        "    # ('lasso_selection', SelectFromModel(LassoCV(cv=2), max_features=500))\n",
        "])\n",
        "\n",
        "X_selected = pipe.fit_transform(X, y)\n",
        "selector = pipe.named_steps['kbest']\n",
        "\n",
        "print(f\"Исходное число признаков: {X.shape[1]}\")\n",
        "print(f\"Число признаков после отбора: {X_selected.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2d5ebe0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Масштабирование данных (важно для линейной регрессии)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.3, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e8e0b579",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE: 0.0131\n",
            "ROC-AUC Score: 0.6138\n",
            "\n",
            "Модель имеет 200 коэффициентов (слишком много для вывода).\n"
          ]
        }
      ],
      "source": [
        "# 4. Создание и обучение модели\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Предсказание и оценка качества\n",
        "y_pred = model.predict(X_test)\n",
        "# y_pred_proba_lin_reg = model.decision_function(X_test)\n",
        "\n",
        "# Метрики\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "# нормализуем значения для roc_auc\n",
        "y_proba = 1 / (1 + np.exp(-y_pred)) # преобразование через сигмойду\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(f\"\\nMSE: {mse:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# (Опционально) Вывод коэффициентов модели\n",
        "if X_selected.shape[1] <= 20:  # Не выводить для слишком большого числа фич\n",
        "    print(\"\\nКоэффициенты модели:\")\n",
        "    # for feature, coef in zip(X.columns[selector.get_support()], model.coef_):\n",
        "    #     print(f\"{feature}: {coef:.4f}\")\n",
        "else:\n",
        "    print(f\"\\nМодель имеет {X_selected.shape[1]} коэффициентов (слишком много для вывода).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61f786ac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.01250972, 0.02264322, 0.01082186, ..., 0.01555858, 0.01401817,\n",
              "       0.01930193], shape=(74392,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee56f1d",
      "metadata": {},
      "source": [
        "Так.... Из полученных метрик следует что вроде бы по MSE результат довольно терпимый и среднеквадратичная ошибка не слишком большая.\n",
        "Касаемо метрики ROC-AUC Score получаем 0.6536 что является лучше чем убычное угадывание(подбрасывание монетки).\n",
        "Из инересного мы не должны использовать LinearRegression, так как она может выдавать значения за пределами [0, 1], но после регуляризации значений, они могут быть использованиы для вычисления метрики. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d750929",
      "metadata": {},
      "source": [
        "Попробуем RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a35beee4",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bed71c2a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.  , 0.  , 0.  , ..., 0.03, 0.  , 0.02], shape=(74392,))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7f3a6d78",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC_AUC_SCORE is 0.5860\n"
          ]
        }
      ],
      "source": [
        "print(f\"ROC_AUC_SCORE is {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a523067",
      "metadata": {},
      "source": [
        "Прогресс, модель достигла случайного угадывания\n",
        "(последние данные ROC_AUC_SCORE is 0.6261, это даже лучше чем просто уадывание по среднему значению)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "003b1165",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.01\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(y_test, y_pred_proba)\n",
        "print(f'MSE: {mse:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d133c2d4",
      "metadata": {},
      "source": [
        "Небольшой апдейт для структуры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f58e5d78",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "45b9dd08",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Отбор признаков: удаляем низковариативные (константные и почти константные)\n",
        "# Сделаем pipeline для более эффективного отбора признаков(их сокращения)\n",
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('kbest', SelectKBest(f_classif, k=100)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestClassifier())\n",
        "    # ('lasso_selection', SelectFromModel(LassoCV(cv=2), max_features=500))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc_metric = roc_auc_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1657a37c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC Score is 0.5904\n"
          ]
        }
      ],
      "source": [
        "print(f\"ROC-AUC Score is {roc_auc_metric:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7551e3d8",
      "metadata": {},
      "source": [
        "А что если заменить RandomForsetClassifier на LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9ade12e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Отбор признаков: удаляем низковариативные (константные и почти константные)\n",
        "# Сделаем pipeline для более эффективного отбора признаков(их сокращения)\n",
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('kbest', SelectKBest(f_classif, k=100)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression())\n",
        "    # ('lasso_selection', SelectFromModel(LassoCV(cv=2), max_features=500))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc_metric = roc_auc_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1fb1f965",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC Score is 0.6158\n"
          ]
        }
      ],
      "source": [
        "print(f\"ROC-AUC Score is {roc_auc_metric:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c997fdf",
      "metadata": {},
      "source": [
        "Вау, метрика подросла)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61619d27",
      "metadata": {},
      "source": [
        "Теперь попробуем GradientBoostingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c06ca331",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Отбор признаков: удаляем низковариативные (константные и почти константные)\n",
        "# Сделаем pipeline для более эффективного отбора признаков(их сокращения)\n",
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('kbest', SelectKBest(f_classif, k=100)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', GradientBoostingClassifier())\n",
        "    # ('lasso_selection', SelectFromModel(LassoCV(cv=2), max_features=500))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc_metric = roc_auc_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8d8ec84b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC Score is 0.6347\n"
          ]
        }
      ],
      "source": [
        "print(f\"ROC-AUC Score is {roc_auc_metric:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "913dd4b5",
      "metadata": {},
      "source": [
        "Попробуем еще одну модель SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "13e780c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Отбор признаков: удаляем низковариативные (константные и почти константные)\n",
        "# Сделаем pipeline для более эффективного отбора признаков(их сокращения)\n",
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('kbest', SelectKBest(f_classif, k=100)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', SVC(probability=True, kernel='rbf', C=1.0, decision_function_shape='ovr'))\n",
        "    # ('lasso_selection', SelectFromModel(LassoCV(cv=2), max_features=500))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc_metric = roc_auc_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "de79ac60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC Score is 0.5873\n"
          ]
        }
      ],
      "source": [
        "print(f\"ROC-AUC Score is {roc_auc_metric:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2a38a4",
      "metadata": {},
      "source": [
        "Начинаем работу с XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1747eeb",
      "metadata": {},
      "source": [
        "Подготовим данные для него"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "57b8cc54",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('kbest', SelectKBest(f_classif, k=150)),\n",
        "])\n",
        "\n",
        "X_selected = pipe.fit_transform(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8ad9b766",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[32m      3\u001b[39m poly = PolynomialFeatures(degree=\u001b[32m2\u001b[39m, interaction_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_poly = \u001b[43mpoly\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_selected\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:564\u001b[39m, in \u001b[36mPolynomialFeatures.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    561\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;66;03m# XP[:, start:end] are terms of degree d - 1\u001b[39;00m\n\u001b[32m    563\u001b[39m     \u001b[38;5;66;03m# that exclude feature #feature_idx.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mXP\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXP\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_col\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnext_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m     current_col = next_col\n\u001b[32m    572\u001b[39m new_index.append(current_col)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
        "X_poly = poly.fit_transform(X_selected)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3e1239d",
      "metadata": {},
      "source": [
        "Для полиномиальных признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d215076",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_poly' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mX_poly\u001b[49m, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m\n\u001b[32m      3\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'X_poly' is not defined"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_poly, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b4ac6c9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7107f09",
      "metadata": {},
      "source": [
        "Попытаемся создать полиномиальные признаки"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8527362c",
      "metadata": {},
      "source": [
        "Присутствуют импорты библиотек и моделей, чтобы лучше понимать что происходит и не возвращаться каждый раз наверх"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fcaa402",
      "metadata": {},
      "source": [
        "Пипец долго считает)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5611634b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = XGBClassifier(objective='binary:logistic', eval_metric='auc', tree_method='hist', device='cuda')\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [500, 1000, 1500, 1700],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.7, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.9],\n",
        "    'reg_alpha': [0, 1],\n",
        "    'reg_lambda': [0, 1]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Лучшие параметры: {grid.best_params_}\")\n",
        "print(f\"Лучший ROC-AUC: {grid.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fe148cc7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "print(xgb.build_info()[\"USE_CUDA\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3a88d158",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    # ('kbest', SelectKBest(f_classif, k=150)),\n",
        "])\n",
        "\n",
        "X_selected = pipe.fit_transform(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f4b7f67",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "62e88969",
      "metadata": {},
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8834233b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 270 candidates, totalling 810 fits\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 635. MiB for an array with shape (66126, 1259) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
            "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 156, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 270, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 36, in _array_indexing\n    return array[key, ...] if axis == 0 else array[:, key]\n           ~~~~~^^^^^^^^^^\n  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\memmap.py\", line 358, in __getitem__\n    res = super().__getitem__(index)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 635. MiB for an array with shape (66126, 1259) and data type float64\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     18\u001b[39m dt = DecisionTreeClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     19\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     20\u001b[39m     estimator=dt,\n\u001b[32m     21\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     26\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 3. Вывод результатов\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЛучшие параметры: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1748\u001b[39m \n\u001b[32m   1749\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    739\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    744\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mMemoryError\u001b[39m: Unable to allocate 635. MiB for an array with shape (66126, 1259) and data type float64"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=dt,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 3. Вывод результатов\n",
        "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
        "print(f\"Лучшая точность (accuracy): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "best_dt = grid_search.best_estimator_\n",
        "y_pred = best_dt.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# # 4. Визуализация\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# plot_tree(\n",
        "#     best_dt,\n",
        "#     filled=True,\n",
        "#     feature_names=[f'Feature {i}' for i in range(X.shape[1])],\n",
        "#     class_names=['Class 0', 'Class 1'],\n",
        "#     rounded=True,\n",
        "#     proportion=True,\n",
        "#     max_depth=3  # Ограничиваем глубину для визуализации\n",
        "# )\n",
        "# plt.title(\"Оптимизированное дерево решений (первые 3 уровня)\")\n",
        "# plt.show()\n",
        "\n",
        "# # 5. Матрица ошибок\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "# plt.figure(figsize=(6, 6))\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "# plt.xlabel('Предсказанные')\n",
        "# plt.ylabel('Фактические')\n",
        "# plt.title('Матрица ошибок')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "af9dd32d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:44:17,554] A new study created in memory with name: no-name-5c2e05e2-aa95-45e2-b95e-c8c8f94f9b62\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b091f384b718438f9e7609a3bb57a9e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:44:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:45:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:45:32,022] Trial 0 finished with value: 0.6332694643376764 and parameters: {'n_estimators': 2655, 'max_depth': 4, 'learning_rate': 0.059606380301557516, 'subsample': 0.815262963337851, 'colsample_bytree': 0.9479400634560914, 'reg_alpha': 9.109134945303335, 'reg_lambda': 5.016289164156637}. Best is trial 0 with value: 0.6332694643376764.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:45:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:47:38,915] Trial 1 finished with value: 0.6390429926995167 and parameters: {'n_estimators': 1471, 'max_depth': 9, 'learning_rate': 0.042999649408740404, 'subsample': 0.7608812230447864, 'colsample_bytree': 0.980344337391491, 'reg_alpha': 9.84185146678722, 'reg_lambda': 9.333641012818747}. Best is trial 1 with value: 0.6390429926995167.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:50:41,405] Trial 2 finished with value: 0.629821726212404 and parameters: {'n_estimators': 2628, 'max_depth': 9, 'learning_rate': 0.05959622766808369, 'subsample': 0.9448693003151365, 'colsample_bytree': 0.9493341697441646, 'reg_alpha': 4.0625444000941835, 'reg_lambda': 2.2665944892313696}. Best is trial 1 with value: 0.6390429926995167.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:50:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:52:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:52:34,828] Trial 3 finished with value: 0.635782393181221 and parameters: {'n_estimators': 1349, 'max_depth': 9, 'learning_rate': 0.03518862799936551, 'subsample': 0.7006473611227791, 'colsample_bytree': 0.7758249685719492, 'reg_alpha': 9.020276063773553, 'reg_lambda': 8.883762142866043}. Best is trial 1 with value: 0.6390429926995167.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:52:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:53:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:53:58,127] Trial 4 finished with value: 0.644305556692548 and parameters: {'n_estimators': 2985, 'max_depth': 4, 'learning_rate': 0.0384051998957243, 'subsample': 0.7089465975273709, 'colsample_bytree': 0.8314402232363078, 'reg_alpha': 7.787192553714581, 'reg_lambda': 5.707927280512944}. Best is trial 4 with value: 0.644305556692548.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:54:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:54:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:54:51,003] Trial 5 finished with value: 0.6630907843337172 and parameters: {'n_estimators': 1999, 'max_depth': 4, 'learning_rate': 0.022942852424607224, 'subsample': 0.7990270653099321, 'colsample_bytree': 0.8338681504538963, 'reg_alpha': 6.979879276053667, 'reg_lambda': 0.07676961956413764}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:54:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:56:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:56:11,209] Trial 6 finished with value: 0.6270573308347616 and parameters: {'n_estimators': 1576, 'max_depth': 7, 'learning_rate': 0.08465766890129577, 'subsample': 0.7420271342808984, 'colsample_bytree': 0.9512844627874624, 'reg_alpha': 0.5514889858387784, 'reg_lambda': 3.7816513454758782}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:56:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:57:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:57:34,955] Trial 7 finished with value: 0.6508047549268774 and parameters: {'n_estimators': 1005, 'max_depth': 9, 'learning_rate': 0.014133354018923676, 'subsample': 0.7827421943694344, 'colsample_bytree': 0.9008185452431265, 'reg_alpha': 6.581390625044554, 'reg_lambda': 1.6011222296587846}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:57:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:58:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:58:30,514] Trial 8 finished with value: 0.6357581442349649 and parameters: {'n_estimators': 2114, 'max_depth': 4, 'learning_rate': 0.06437152675423238, 'subsample': 0.9515315907105846, 'colsample_bytree': 0.9511502389948221, 'reg_alpha': 6.191182038447768, 'reg_lambda': 4.863407666322037}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:58:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [20:59:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 20:59:44,076] Trial 9 finished with value: 0.6388833434670362 and parameters: {'n_estimators': 2058, 'max_depth': 6, 'learning_rate': 0.03578313281033445, 'subsample': 0.953352074969632, 'colsample_bytree': 0.7722236138182492, 'reg_alpha': 4.000752309794736, 'reg_lambda': 7.827065675777966}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:59:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:00:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:00:47,259] Trial 10 finished with value: 0.6597074981710962 and parameters: {'n_estimators': 1799, 'max_depth': 6, 'learning_rate': 0.010379859333975668, 'subsample': 0.869752030029241, 'colsample_bytree': 0.7005924508880585, 'reg_alpha': 1.9688212691001885, 'reg_lambda': 0.32423399637624506}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:00:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:01:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:01:50,344] Trial 11 finished with value: 0.6558610323278766 and parameters: {'n_estimators': 1827, 'max_depth': 6, 'learning_rate': 0.012492515304400136, 'subsample': 0.8773593318292372, 'colsample_bytree': 0.7087349123368188, 'reg_alpha': 1.3473954442515357, 'reg_lambda': 0.2154464288903689}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:01:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:02:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:02:38,232] Trial 12 finished with value: 0.6568609292543505 and parameters: {'n_estimators': 2211, 'max_depth': 3, 'learning_rate': 0.02045247379542601, 'subsample': 0.8765125151747354, 'colsample_bytree': 0.7063195609587165, 'reg_alpha': 2.2506819382232006, 'reg_lambda': 0.22542077482495237}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:02:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:04:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:04:08,374] Trial 13 finished with value: 0.642263931856864 and parameters: {'n_estimators': 1856, 'max_depth': 7, 'learning_rate': 0.02495369606774313, 'subsample': 0.8379471361454914, 'colsample_bytree': 0.8516582856689722, 'reg_alpha': 2.741112499749589, 'reg_lambda': 2.2283467442590297}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:04:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:05:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:05:20,923] Trial 14 finished with value: 0.6458480625526065 and parameters: {'n_estimators': 2319, 'max_depth': 5, 'learning_rate': 0.02645820321515994, 'subsample': 0.8887044764939083, 'colsample_bytree': 0.7643260486999739, 'reg_alpha': 5.717077326420888, 'reg_lambda': 1.278158718623775}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:05:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:06:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:06:19,434] Trial 15 finished with value: 0.6321248799646151 and parameters: {'n_estimators': 1679, 'max_depth': 5, 'learning_rate': 0.09436656412328294, 'subsample': 0.8046868729516651, 'colsample_bytree': 0.8411198098528103, 'reg_alpha': 4.607440887461953, 'reg_lambda': 3.547511396519116}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:06:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:07:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:07:00,951] Trial 16 finished with value: 0.6574225001196943 and parameters: {'n_estimators': 1274, 'max_depth': 3, 'learning_rate': 0.010554803073800956, 'subsample': 0.9952776176930571, 'colsample_bytree': 0.8066712759595599, 'reg_alpha': 7.404177508614204, 'reg_lambda': 0.14415126141932882}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:07:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:08:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:08:56,906] Trial 17 finished with value: 0.6357741913317522 and parameters: {'n_estimators': 2459, 'max_depth': 5, 'learning_rate': 0.04665293867587121, 'subsample': 0.8437957572195214, 'colsample_bytree': 0.8789773012026251, 'reg_alpha': 0.062275802699906624, 'reg_lambda': 6.596096939140496}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:08:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:11:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:11:13,343] Trial 18 finished with value: 0.6274739041646913 and parameters: {'n_estimators': 1733, 'max_depth': 8, 'learning_rate': 0.0713839850451398, 'subsample': 0.908797564257225, 'colsample_bytree': 0.745890954095203, 'reg_alpha': 3.1112247291539483, 'reg_lambda': 3.0224237476917506}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:11:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [21:12:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:12:26,242] Trial 19 finished with value: 0.6398122145477305 and parameters: {'n_estimators': 1946, 'max_depth': 6, 'learning_rate': 0.026109550332774945, 'subsample': 0.8114813380181849, 'colsample_bytree': 0.9042374408104935, 'reg_alpha': 1.776944664473156, 'reg_lambda': 1.2545769878477766}. Best is trial 5 with value: 0.6630907843337172.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:12:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[W 2025-04-24 21:12:58,786] Trial 20 failed with parameters: {'n_estimators': 1179, 'max_depth': 8, 'learning_rate': 0.048837807396312494, 'subsample': 0.9199681232785383, 'colsample_bytree': 0.7278136145197325, 'reg_alpha': 5.293441026305976, 'reg_lambda': 0.9337493217727213} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_4796\\2749560374.py\", line 19, in objective\n",
            "    model.fit(X_train, y_train)\n",
            "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1682, in fit\n",
            "    self._Booster = train(\n",
            "                    ^^^^^^\n",
            "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py\", line 183, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 2247, in update\n",
            "    _LIB.XGBoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2025-04-24 21:12:58,797] Trial 20 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m roc_auc_score(y_test, y_proba)\n\u001b[32m     23\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЛучший ROC-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЛучшие параметры: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      5\u001b[39m params = {\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m, \u001b[32m3000\u001b[39m),\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m10\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreg_lambda\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mreg_lambda\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m10\u001b[39m),\n\u001b[32m     13\u001b[39m }\n\u001b[32m     15\u001b[39m model = XGBClassifier(**params, objective=\u001b[33m'\u001b[39m\u001b[33mbinary:logistic\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     16\u001b[39m                       scale_pos_weight=\u001b[32m10\u001b[39m, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, tree_method=\u001b[33m'\u001b[39m\u001b[33mgpu_hist\u001b[39m\u001b[33m'\u001b[39m, eval_metric=\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m y_proba = model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m roc_auc_score(y_test, y_proba)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 1000, 3000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "    }\n",
        "    \n",
        "    model = XGBClassifier(**params, objective='binary:logistic', \n",
        "                          scale_pos_weight=10, device='cuda', tree_method='gpu_hist', eval_metric='auc')\n",
        "    \n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    return roc_auc_score(y_test, y_proba)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "print(f\"Лучший ROC-AUC: {study.best_value:.4f}\")\n",
        "print(f\"Лучшие параметры: {study.best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cee2d5da",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 1329,\n",
              " 'max_depth': 5,\n",
              " 'learning_rate': 0.011727218131778093,\n",
              " 'subsample': 0.8076087244185466,\n",
              " 'colsample_bytree': 0.7009149718891257,\n",
              " 'reg_alpha': 3.8018706948423153,\n",
              " 'reg_lambda': 6.485312518852529}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params = study.best_params\n",
        "best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0141ed",
      "metadata": {},
      "source": [
        "Был сбой, но best_params удалось сохранить в save.txt так что скопирую их оттуда"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7aab5059",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = {\n",
        "    \"n_estimators\": 1329,\n",
        "    \"max_depth\": 5,\n",
        "    \"learning_rate\": 0.011727218131778093,\n",
        "    \"subsample\": 0.8076087244185466,\n",
        "    \"colsample_bytree\": 0.7009149718891257,\n",
        "    \"reg_alpha\": 3.8018706948423153,\n",
        "    \"reg_lambda\": 6.485312518852529\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0f34065a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# generate output data\n",
        "X_true_test_df = pd.read_csv('./datasets/test/test.csv')\n",
        "X_true_test = X_true_test_df.drop(columns=['index'])\n",
        "indexes = X_true_test_df['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "30a6d121",
      "metadata": {},
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f6f49821",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "681fe94c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC is 0.6694\n"
          ]
        }
      ],
      "source": [
        "pipe = Pipeline([\n",
        "    ('selector', VarianceThreshold(threshold=0.01)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', XGBClassifier(**best_params, objective='binary:logistic', \n",
        "                          scale_pos_weight=10, device='cuda', tree_method='hist', eval_metric='auc')),\n",
        "    \n",
        "    # ('kbest', SelectKBest(f_classif, k=500)),\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_train_pred_proba)\n",
        "print(f'ROC-AUC is {roc_auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7ec31316",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.03445641, 0.11509901, 0.17070378, ..., 0.02926016, 0.15941654,\n",
              "       0.05215071], shape=(106274,), dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_pred_proba = pipe.predict_proba(X_true_test)[:, 1]\n",
        "y_test_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ba961d05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         index         0\n",
            "0       194357  0.034456\n",
            "1       313222  0.115099\n",
            "2       321873  0.170704\n",
            "3       118689  0.089138\n",
            "4       342561  0.055293\n",
            "...        ...       ...\n",
            "106269  239350  0.143143\n",
            "106270  324235  0.121266\n",
            "106271  108007  0.029260\n",
            "106272  236241  0.159417\n",
            "106273  185650  0.052151\n",
            "\n",
            "[106274 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "output = pd.concat([indexes, pd.Series(y_test_pred_proba)], axis=1)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b61e92d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "output.to_csv(\"output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37305544",
      "metadata": {},
      "source": [
        "Пытаемся сделать что-то с помощью CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3947fd7f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b94d41429364eeebe4691ed91c2ba9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.5787868\tbest: 0.5787868 (0)\ttotal: 23.8ms\tremaining: 47.6s\n",
            "100:\ttest: 0.6296715\tbest: 0.6302694 (47)\ttotal: 2.1s\tremaining: 39.6s\n",
            "200:\ttest: 0.6333683\tbest: 0.6333683 (200)\ttotal: 3.98s\tremaining: 35.6s\n",
            "300:\ttest: 0.6328608\tbest: 0.6339951 (278)\ttotal: 5.8s\tremaining: 32.8s\n",
            "bestTest = 0.6339950562\n",
            "bestIteration = 278\n",
            "Shrink model to first 279 iterations.\n",
            "Validation ROC-AUC: 0.6340\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Подготовка данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_pool = Pool(X_train, y_train)\n",
        "val_pool = Pool(X_test, y_test)\n",
        "\n",
        "# Параметры модели\n",
        "model = CatBoostClassifier(\n",
        "    iterations=2000,                # Больше итераций для сложных данных\n",
        "    learning_rate=0.03,             # Меньше lr → больше trees\n",
        "    depth=6,                        # Оптимальная глубина для баланса\n",
        "    l2_leaf_reg=5,                  # Сильная L2-регуляризация против шума\n",
        "    random_strength=1,              # Защита от переобучения\n",
        "    bagging_temperature=0.5,        # Случайность в подвыборках\n",
        "    grow_policy='Lossguide',        # Лучше для дисбаланса\n",
        "    eval_metric='AUC',              # Оптимизация ROC-AUC\n",
        "    early_stopping_rounds=100,      # Стоп, если AUC не растет\n",
        "    scale_pos_weight=(len(y_train) / sum(y_train)),  # Вес для положительного класса\n",
        "    verbose=100,                    # Лог каждые 100 итераций\n",
        "    task_type='GPU'                 # Использует GPU, если доступен\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "model.fit(train_pool, eval_set=val_pool, plot=True)\n",
        "\n",
        "# Предсказание\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "print(f\"Validation ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ccf03cfa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 21:45:04,281] A new study created in memory with name: no-name-7db719bc-b730-416b-9da0-6d470f232607\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:45:31,394] Trial 0 finished with value: 0.658133797375061 and parameters: {'iterations': 2367, 'depth': 5, 'lr': 0.0326279719029825, 'l2': 6.062970171146687, 'random_strength': 1.5807084431906044}. Best is trial 0 with value: 0.658133797375061.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:46:05,759] Trial 1 finished with value: 0.6514659728367148 and parameters: {'iterations': 2135, 'depth': 9, 'lr': 0.07034581566405182, 'l2': 9.912412318392336, 'random_strength': 1.4629757198977675}. Best is trial 0 with value: 0.658133797375061.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:46:23,907] Trial 2 finished with value: 0.6488013020257731 and parameters: {'iterations': 1177, 'depth': 6, 'lr': 0.01656073849715368, 'l2': 4.183122969489421, 'random_strength': 0.6969570214570848}. Best is trial 0 with value: 0.658133797375061.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:46:44,568] Trial 3 finished with value: 0.6430913263689862 and parameters: {'iterations': 2863, 'depth': 9, 'lr': 0.010431160083902524, 'l2': 1.9513928478026425, 'random_strength': 0.7072025840737808}. Best is trial 0 with value: 0.658133797375061.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:47:54,940] Trial 4 finished with value: 0.6649347585511955 and parameters: {'iterations': 1755, 'depth': 9, 'lr': 0.01325717090062381, 'l2': 2.0004538493627297, 'random_strength': 1.889420128177541}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:48:01,638] Trial 5 finished with value: 0.6386352413967095 and parameters: {'iterations': 2502, 'depth': 6, 'lr': 0.015646153211687656, 'l2': 6.783263784055685, 'random_strength': 1.0304746163428968}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:48:07,268] Trial 6 finished with value: 0.6292249447607764 and parameters: {'iterations': 1890, 'depth': 4, 'lr': 0.012581040602998342, 'l2': 8.482445864435618, 'random_strength': 0.7475789202570875}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:48:35,666] Trial 7 finished with value: 0.6438856654121713 and parameters: {'iterations': 2100, 'depth': 9, 'lr': 0.012745456761597801, 'l2': 5.633189387871743, 'random_strength': 0.41535360294214796}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:49:11,655] Trial 8 finished with value: 0.6545296194366654 and parameters: {'iterations': 1891, 'depth': 7, 'lr': 0.010462248775714722, 'l2': 3.230949051036918, 'random_strength': 0.8850206007255471}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:49:19,490] Trial 9 finished with value: 0.6537774679783672 and parameters: {'iterations': 540, 'depth': 5, 'lr': 0.08295700828011057, 'l2': 5.745820786907711, 'random_strength': 0.5862706227693694}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:50:40,074] Trial 10 finished with value: 0.6625763004567236 and parameters: {'iterations': 1391, 'depth': 10, 'lr': 0.02714208709716463, 'l2': 1.2887010668276495, 'random_strength': 1.934745868326402}. Best is trial 4 with value: 0.6649347585511955.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:52:00,290] Trial 11 finished with value: 0.6657282603545481 and parameters: {'iterations': 1202, 'depth': 10, 'lr': 0.026379715666624164, 'l2': 1.1913891243046328, 'random_strength': 1.8870277617828881}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:53:03,032] Trial 12 finished with value: 0.6622562577785782 and parameters: {'iterations': 1285, 'depth': 10, 'lr': 0.028656768555164608, 'l2': 2.9207983928231664, 'random_strength': 1.9576559886973164}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:53:19,099] Trial 13 finished with value: 0.6581354253414016 and parameters: {'iterations': 782, 'depth': 8, 'lr': 0.045067124651513094, 'l2': 1.17693318181255, 'random_strength': 1.4965690779356915}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:54:00,358] Trial 14 finished with value: 0.6613414957395036 and parameters: {'iterations': 1538, 'depth': 8, 'lr': 0.023070202307835942, 'l2': 4.041262186631608, 'random_strength': 1.7206514693465778}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:55:00,778] Trial 15 finished with value: 0.6643204415764121 and parameters: {'iterations': 947, 'depth': 10, 'lr': 0.050502488624587234, 'l2': 2.468979689094414, 'random_strength': 1.2428053753124975}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:55:07,236] Trial 16 finished with value: 0.6389881534904963 and parameters: {'iterations': 1592, 'depth': 8, 'lr': 0.019296391665311285, 'l2': 4.441799397074179, 'random_strength': 0.14920186800822755}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:55:40,283] Trial 17 finished with value: 0.6566711859012285 and parameters: {'iterations': 1010, 'depth': 9, 'lr': 0.03597848394581079, 'l2': 1.7312188764908318, 'random_strength': 1.2503767117170776}. Best is trial 11 with value: 0.6657282603545481.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:57:26,837] Trial 18 finished with value: 0.6665794541841277 and parameters: {'iterations': 1709, 'depth': 10, 'lr': 0.020662981654056042, 'l2': 3.2924767473331915, 'random_strength': 1.8172012963327777}. Best is trial 18 with value: 0.6665794541841277.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:58:01,719] Trial 19 finished with value: 0.6514102033612141 and parameters: {'iterations': 507, 'depth': 10, 'lr': 0.022066165239456658, 'l2': 3.45121222290004, 'random_strength': 1.740485164056153}. Best is trial 18 with value: 0.6665794541841277.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 21:58:24,699] Trial 20 finished with value: 0.6560645436249086 and parameters: {'iterations': 1480, 'depth': 7, 'lr': 0.039361239768181185, 'l2': 4.856334666189485, 'random_strength': 1.2230352700043414}. Best is trial 18 with value: 0.6665794541841277.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:00:23,720] Trial 21 finished with value: 0.6650150405484554 and parameters: {'iterations': 1787, 'depth': 10, 'lr': 0.016834020431314423, 'l2': 2.2040834418850506, 'random_strength': 1.7860384360396102}. Best is trial 18 with value: 0.6665794541841277.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:01:50,943] Trial 22 finished with value: 0.6643704433997345 and parameters: {'iterations': 1736, 'depth': 10, 'lr': 0.01941345094884441, 'l2': 2.599414533952715, 'random_strength': 1.7148233295495425}. Best is trial 18 with value: 0.6665794541841277.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:02:48,671] Trial 23 finished with value: 0.6616161259089633 and parameters: {'iterations': 1133, 'depth': 10, 'lr': 0.02478582111377629, 'l2': 1.0481364574286811, 'random_strength': 1.9944798712771135}. Best is trial 18 with value: 0.6665794541841277.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:04:14,797] Trial 24 finished with value: 0.667512837057252 and parameters: {'iterations': 2162, 'depth': 9, 'lr': 0.016967553477829106, 'l2': 3.771956105868858, 'random_strength': 1.4003566003553634}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:05:13,121] Trial 25 finished with value: 0.662318585632766 and parameters: {'iterations': 2554, 'depth': 8, 'lr': 0.019775648658598467, 'l2': 3.4237353305465446, 'random_strength': 1.4307988007917334}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:05:59,019] Trial 26 finished with value: 0.6594723888226125 and parameters: {'iterations': 2107, 'depth': 9, 'lr': 0.032273509781193914, 'l2': 5.033755206272181, 'random_strength': 1.404505968820482}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:06:15,407] Trial 27 finished with value: 0.6414236376495465 and parameters: {'iterations': 2972, 'depth': 9, 'lr': 0.015583791225506145, 'l2': 7.672862100346647, 'random_strength': 1.6452643572802281}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:07:30,174] Trial 28 finished with value: 0.661412149478691 and parameters: {'iterations': 2294, 'depth': 10, 'lr': 0.02669960886725585, 'l2': 3.8102250000746913, 'random_strength': 1.825345128972086}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:07:52,687] Trial 29 finished with value: 0.6579427981621904 and parameters: {'iterations': 2430, 'depth': 7, 'lr': 0.051837993689681346, 'l2': 6.33438192551586, 'random_strength': 1.58551177600146}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:08:23,459] Trial 30 finished with value: 0.6574902855372339 and parameters: {'iterations': 2693, 'depth': 8, 'lr': 0.03208659333086624, 'l2': 4.9560455975949615, 'random_strength': 1.0578467940609395}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:10:27,925] Trial 31 finished with value: 0.6672951236919523 and parameters: {'iterations': 1907, 'depth': 10, 'lr': 0.01735067769676719, 'l2': 2.5990367692879417, 'random_strength': 1.8482015974866355}. Best is trial 24 with value: 0.667512837057252.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:12:19,705] Trial 32 finished with value: 0.6689002519905842 and parameters: {'iterations': 2279, 'depth': 10, 'lr': 0.020761570500590826, 'l2': 2.7682070244182237, 'random_strength': 1.6047401068931464}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:13:10,473] Trial 33 finished with value: 0.6625459582650207 and parameters: {'iterations': 2268, 'depth': 9, 'lr': 0.0212367970150467, 'l2': 2.8445274452578753, 'random_strength': 1.5379971336815732}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:15:19,493] Trial 34 finished with value: 0.6686617781783298 and parameters: {'iterations': 1985, 'depth': 10, 'lr': 0.01727575735601637, 'l2': 3.6412082662140786, 'random_strength': 1.3604111329832784}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:15:34,472] Trial 35 finished with value: 0.642003643295644 and parameters: {'iterations': 1965, 'depth': 9, 'lr': 0.01420183724590074, 'l2': 4.377286336765912, 'random_strength': 1.1334723816042296}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:17:54,996] Trial 36 finished with value: 0.6658290857365837 and parameters: {'iterations': 2233, 'depth': 10, 'lr': 0.01751445120811609, 'l2': 3.8215174302659034, 'random_strength': 1.365728072697777}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:18:02,267] Trial 37 finished with value: 0.6378659420262891 and parameters: {'iterations': 2690, 'depth': 6, 'lr': 0.01144943022057538, 'l2': 9.985543988656216, 'random_strength': 1.320814930240656}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:19:11,378] Trial 38 finished with value: 0.6654041555127715 and parameters: {'iterations': 2012, 'depth': 9, 'lr': 0.014189613225987928, 'l2': 1.8899408849998185, 'random_strength': 1.6038233820516348}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:20:16,846] Trial 39 finished with value: 0.666740824409597 and parameters: {'iterations': 2163, 'depth': 9, 'lr': 0.017500033187433713, 'l2': 2.8979700773271313, 'random_strength': 0.9018753062776961}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:21:25,869] Trial 40 finished with value: 0.6655543470360346 and parameters: {'iterations': 2366, 'depth': 9, 'lr': 0.015128127908164752, 'l2': 2.3057231302907715, 'random_strength': 1.5129480414557248}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:22:43,522] Trial 41 finished with value: 0.6631255607956434 and parameters: {'iterations': 2162, 'depth': 9, 'lr': 0.017955410711085612, 'l2': 2.9181226185398255, 'random_strength': 0.8057811474098757}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:23:10,406] Trial 42 finished with value: 0.6423863239168038 and parameters: {'iterations': 1997, 'depth': 10, 'lr': 0.012980371403731027, 'l2': 3.586367061953865, 'random_strength': 0.9148191113001679}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:23:15,008] Trial 43 finished with value: 0.6268580987635395 and parameters: {'iterations': 1859, 'depth': 4, 'lr': 0.011094526418800143, 'l2': 1.755821946069272, 'random_strength': 0.5489107864378735}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:23:31,570] Trial 44 finished with value: 0.6395913847897213 and parameters: {'iterations': 2560, 'depth': 9, 'lr': 0.01723883480229757, 'l2': 9.17097925144726, 'random_strength': 1.0318215120514975}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:24:47,333] Trial 45 finished with value: 0.6618720732266082 and parameters: {'iterations': 2125, 'depth': 10, 'lr': 0.023124596440421228, 'l2': 2.8229531065635802, 'random_strength': 1.1500632476587056}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:24:58,692] Trial 46 finished with value: 0.6353093061626061 and parameters: {'iterations': 2375, 'depth': 8, 'lr': 0.01864530918425391, 'l2': 4.500703650722862, 'random_strength': 1.652812003203367}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:26:47,111] Trial 47 finished with value: 0.6605857627552558 and parameters: {'iterations': 1660, 'depth': 10, 'lr': 0.011838849442724389, 'l2': 3.092675955316736, 'random_strength': 1.3401132833899634}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:28:01,658] Trial 48 finished with value: 0.6607175815155306 and parameters: {'iterations': 1890, 'depth': 9, 'lr': 0.014183976646153467, 'l2': 5.40734277111934, 'random_strength': 0.9482845997092608}. Best is trial 32 with value: 0.6689002519905842.\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "[I 2025-04-24 22:30:16,227] Trial 49 finished with value: 0.6623722309998034 and parameters: {'iterations': 2039, 'depth': 10, 'lr': 0.010021010324488216, 'l2': 1.5684238883418462, 'random_strength': 1.453656909129912}. Best is trial 32 with value: 0.6689002519905842.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'iterations': 2279, 'depth': 10, 'lr': 0.020761570500590826, 'l2': 2.7682070244182237, 'random_strength': 1.6047401068931464}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 500, 3000),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'learning_rate': trial.suggest_float('lr', 0.01, 0.1, log=True),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2', 1, 10),\n",
        "        'random_strength': trial.suggest_float('random_strength', 0.1, 2),\n",
        "    }\n",
        "    model = CatBoostClassifier(\n",
        "        **params,\n",
        "        eval_metric='AUC',\n",
        "        early_stopping_rounds=100,\n",
        "        verbose=False,\n",
        "        task_type='GPU'\n",
        "    )\n",
        "    model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    return roc_auc_score(y_test, y_proba)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "print(study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "796b16cb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'iterations': 2279,\n",
              " 'depth': 10,\n",
              " 'learning_rate': 0.020761570500590826,\n",
              " 'l2_leaf_reg': 2.7682070244182237,\n",
              " 'random_strength': 1.6047401068931464}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params = study.best_params\n",
        "best_params = {\n",
        "    'iterations': 2279,\n",
        "    'depth': 10,\n",
        "    'learning_rate': 0.020761570500590826,\n",
        "    'l2_leaf_reg': 2.7682070244182237,\n",
        "    'random_strength': 1.6047401068931464\n",
        "}\n",
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "795840da",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC is 0.6635\n"
          ]
        }
      ],
      "source": [
        "model = CatBoostClassifier(\n",
        "        **best_params,\n",
        "        eval_metric='AUC',\n",
        "        verbose=False,\n",
        "        task_type='GPU',\n",
        "        # auto_class_weights='Balanced',  # Автовес\n",
        "        # scale_pos_weight=len(y[y==0]) / len(y[y==1])  # Ручной расчет\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC is {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5dea9274",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>194357</td>\n",
              "      <td>0.007791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>313222</td>\n",
              "      <td>0.013328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>321873</td>\n",
              "      <td>0.026616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118689</td>\n",
              "      <td>0.015499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>342561</td>\n",
              "      <td>0.006180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106269</th>\n",
              "      <td>239350</td>\n",
              "      <td>0.022315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106270</th>\n",
              "      <td>324235</td>\n",
              "      <td>0.009734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106271</th>\n",
              "      <td>108007</td>\n",
              "      <td>0.004120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106272</th>\n",
              "      <td>236241</td>\n",
              "      <td>0.017185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106273</th>\n",
              "      <td>185650</td>\n",
              "      <td>0.005244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106274 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index         0\n",
              "0       194357  0.007791\n",
              "1       313222  0.013328\n",
              "2       321873  0.026616\n",
              "3       118689  0.015499\n",
              "4       342561  0.006180\n",
              "...        ...       ...\n",
              "106269  239350  0.022315\n",
              "106270  324235  0.009734\n",
              "106271  108007  0.004120\n",
              "106272  236241  0.017185\n",
              "106273  185650  0.005244\n",
              "\n",
              "[106274 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true_pred = model.predict_proba(X_true_test)[:, 1]\n",
        "output = pd.concat([indexes, pd.Series(y_true_pred)], axis=1)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f153a8ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "output.to_csv(\"output2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b61639d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC is 0.6162\n"
          ]
        }
      ],
      "source": [
        "print(f\"ROC-AUC is {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2699958a",
      "metadata": {},
      "source": [
        "Попробуем обучить LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a006834",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ebd27aa6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation ROC-AUC: 0.6239\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model = LGBMClassifier(\n",
        "    boosting_type='goss',          # Алгоритм, устойчивый к шуму\n",
        "    n_estimators=2000,             # Больше деревьев для сложных данных\n",
        "    learning_rate=0.03,            # Меньше шаг → лучше обобщение\n",
        "    max_depth=6,                   # Оптимальная глубина\n",
        "    num_leaves=31,                 # Аналог max_depth (2^max_depth ≈ num_leaves)\n",
        "    min_child_samples=20,          # Защита от переобучения\n",
        "    reg_alpha=1.0,                 # L1-регуляризация\n",
        "    reg_lambda=1.0,                # L2-регуляризация\n",
        "    subsample=0.8,                 # Случайная подвыборка строк\n",
        "    colsample_bytree=0.7,          # Случайная подвыборка фичей\n",
        "    scale_pos_weight=len(y[y==0]) / len(y[y==1]),  # Вес для дисбаланса\n",
        "    objective='binary',            # Для бинарной классификации\n",
        "    metric='auc',                  # Оптимизация ROC-AUC\n",
        "    random_state=42,\n",
        "    n_jobs=-1                      # Использовать все ядра CPU\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_metric='auc',\n",
        ")\n",
        "\n",
        "# Предсказание\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "print(f\"Validation ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1eae7e81",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-25 00:33:14,483] A new study created in memory with name: no-name-76e925da-2901-4f84-a516-0baf97cc78e6\n",
            "[I 2025-04-25 00:35:38,764] Trial 0 finished with value: 0.6578591827100424 and parameters: {'n_estimators': 2138, 'learning_rate': 0.015273447895870918, 'num_leaves': 43, 'max_depth': 7, 'reg_alpha': 2.6230231598835614, 'reg_lambda': 5.599091772567814, 'subsample': 0.8306505990963498}. Best is trial 0 with value: 0.6578591827100424.\n",
            "[I 2025-04-25 00:36:37,408] Trial 1 finished with value: 0.6552442656513614 and parameters: {'n_estimators': 1772, 'learning_rate': 0.01845617989759553, 'num_leaves': 23, 'max_depth': 3, 'reg_alpha': 4.920343565753955, 'reg_lambda': 4.221858908428714, 'subsample': 0.8197623374073901}. Best is trial 0 with value: 0.6578591827100424.\n",
            "[I 2025-04-25 00:38:31,911] Trial 2 finished with value: 0.6474439036908757 and parameters: {'n_estimators': 3687, 'learning_rate': 0.0017454633637403176, 'num_leaves': 49, 'max_depth': 3, 'reg_alpha': 0.228086623732331, 'reg_lambda': 8.660081337259088, 'subsample': 0.6701234166590962}. Best is trial 0 with value: 0.6578591827100424.\n",
            "[I 2025-04-25 00:40:14,080] Trial 3 finished with value: 0.6563414684516868 and parameters: {'n_estimators': 3226, 'learning_rate': 0.009263216428011893, 'num_leaves': 40, 'max_depth': 3, 'reg_alpha': 7.450942227878727, 'reg_lambda': 3.8967511285521637, 'subsample': 0.863287119341031}. Best is trial 0 with value: 0.6578591827100424.\n",
            "[I 2025-04-25 00:41:50,443] Trial 4 finished with value: 0.6462350844173418 and parameters: {'n_estimators': 2968, 'learning_rate': 0.002046550865410825, 'num_leaves': 28, 'max_depth': 3, 'reg_alpha': 4.175736556052636, 'reg_lambda': 7.930191907592418, 'subsample': 0.7556519619283903}. Best is trial 0 with value: 0.6578591827100424.\n",
            "[I 2025-04-25 00:42:50,918] Trial 5 finished with value: 0.6567561502397731 and parameters: {'n_estimators': 1443, 'learning_rate': 0.010191053192560891, 'num_leaves': 47, 'max_depth': 4, 'reg_alpha': 4.119353682995602, 'reg_lambda': 2.737439826380281, 'subsample': 0.8375995512537305}. Best is trial 0 with value: 0.6578591827100424.\n",
            "[I 2025-04-25 00:46:55,562] Trial 6 finished with value: 0.6611195186528351 and parameters: {'n_estimators': 3491, 'learning_rate': 0.002184063744322057, 'num_leaves': 50, 'max_depth': 7, 'reg_alpha': 3.4302198555148156, 'reg_lambda': 0.85442981732756, 'subsample': 0.8324259167622675}. Best is trial 6 with value: 0.6611195186528351.\n",
            "[I 2025-04-25 00:49:49,242] Trial 7 finished with value: 0.6626752032880332 and parameters: {'n_estimators': 3355, 'learning_rate': 0.003209209825211339, 'num_leaves': 43, 'max_depth': 5, 'reg_alpha': 9.34576510786085, 'reg_lambda': 5.228390107254302, 'subsample': 0.744883185354381}. Best is trial 7 with value: 0.6626752032880332.\n",
            "[I 2025-04-25 00:52:20,505] Trial 8 finished with value: 0.6320065965816303 and parameters: {'n_estimators': 3637, 'learning_rate': 0.08591905904114323, 'num_leaves': 40, 'max_depth': 6, 'reg_alpha': 1.9032620906271476, 'reg_lambda': 3.066608016610469, 'subsample': 0.6710888250204322}. Best is trial 7 with value: 0.6626752032880332.\n",
            "[I 2025-04-25 00:53:50,785] Trial 9 finished with value: 0.6468785807507276 and parameters: {'n_estimators': 2412, 'learning_rate': 0.039992181532209355, 'num_leaves': 29, 'max_depth': 4, 'reg_alpha': 1.8086957286063043, 'reg_lambda': 9.513620899899653, 'subsample': 0.6584773745839757}. Best is trial 7 with value: 0.6626752032880332.\n",
            "[I 2025-04-25 00:56:17,749] Trial 10 finished with value: 0.6624443886698008 and parameters: {'n_estimators': 2848, 'learning_rate': 0.004636160515379823, 'num_leaves': 35, 'max_depth': 5, 'reg_alpha': 9.888566173612446, 'reg_lambda': 6.2965651321250045, 'subsample': 0.6027132488531792}. Best is trial 7 with value: 0.6626752032880332.\n",
            "[I 2025-04-25 00:58:44,522] Trial 11 finished with value: 0.6647478835197215 and parameters: {'n_estimators': 2830, 'learning_rate': 0.005291079947579477, 'num_leaves': 33, 'max_depth': 5, 'reg_alpha': 9.956648709733724, 'reg_lambda': 6.385657899803955, 'subsample': 0.6057651516893421}. Best is trial 11 with value: 0.6647478835197215.\n",
            "[I 2025-04-25 01:01:06,338] Trial 12 finished with value: 0.6612966103818235 and parameters: {'n_estimators': 2695, 'learning_rate': 0.004202322670720824, 'num_leaves': 34, 'max_depth': 5, 'reg_alpha': 9.935715924930212, 'reg_lambda': 7.018585520852055, 'subsample': 0.7431544359960472}. Best is trial 11 with value: 0.6647478835197215.\n",
            "[I 2025-04-25 01:05:09,274] Trial 13 finished with value: 0.6656930342638231 and parameters: {'n_estimators': 3961, 'learning_rate': 0.004466832100816834, 'num_leaves': 36, 'max_depth': 6, 'reg_alpha': 7.575182571126268, 'reg_lambda': 5.2385252702476715, 'subsample': 0.7471607403821102}. Best is trial 13 with value: 0.6656930342638231.\n",
            "[I 2025-04-25 01:10:01,894] Trial 14 finished with value: 0.6553842242433398 and parameters: {'n_estimators': 3978, 'learning_rate': 0.001053425090563886, 'num_leaves': 33, 'max_depth': 8, 'reg_alpha': 7.121073498504015, 'reg_lambda': 7.129545889589555, 'subsample': 0.623510371572275}. Best is trial 13 with value: 0.6656930342638231.\n",
            "[I 2025-04-25 01:11:03,886] Trial 15 finished with value: 0.658548882278622 and parameters: {'n_estimators': 1054, 'learning_rate': 0.0069256723560609515, 'num_leaves': 20, 'max_depth': 6, 'reg_alpha': 7.667564106238551, 'reg_lambda': 0.8930672005391083, 'subsample': 0.898700951541705}. Best is trial 13 with value: 0.6656930342638231.\n",
            "[I 2025-04-25 01:13:20,165] Trial 16 finished with value: 0.6554967244697048 and parameters: {'n_estimators': 2123, 'learning_rate': 0.024403379613542536, 'num_leaves': 29, 'max_depth': 7, 'reg_alpha': 8.455863720049438, 'reg_lambda': 4.492681217112155, 'subsample': 0.7191766041931029}. Best is trial 13 with value: 0.6656930342638231.\n",
            "[I 2025-04-25 01:15:50,974] Trial 17 finished with value: 0.6661263989037243 and parameters: {'n_estimators': 2409, 'learning_rate': 0.0057080573740828896, 'num_leaves': 38, 'max_depth': 6, 'reg_alpha': 6.282970753804139, 'reg_lambda': 2.7446601336245817, 'subsample': 0.7062107263823818}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:18:49,625] Trial 18 finished with value: 0.6624537223434875 and parameters: {'n_estimators': 2407, 'learning_rate': 0.002954717301009906, 'num_leaves': 38, 'max_depth': 8, 'reg_alpha': 6.314875838234108, 'reg_lambda': 1.963365395186747, 'subsample': 0.7802568011175085}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:20:58,619] Trial 19 finished with value: 0.6517782632941902 and parameters: {'n_estimators': 1846, 'learning_rate': 0.0011770819207661987, 'num_leaves': 43, 'max_depth': 6, 'reg_alpha': 6.072902075834595, 'reg_lambda': 0.12472184437853251, 'subsample': 0.7064873578612199}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:24:31,111] Trial 20 finished with value: 0.655138571874745 and parameters: {'n_estimators': 3118, 'learning_rate': 0.009598995265284588, 'num_leaves': 38, 'max_depth': 7, 'reg_alpha': 5.339484567900623, 'reg_lambda': 3.0934806549486327, 'subsample': 0.7887848456062274}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:28:35,516] Trial 21 finished with value: 0.6643819476952089 and parameters: {'n_estimators': 3973, 'learning_rate': 0.005834969389498196, 'num_leaves': 32, 'max_depth': 6, 'reg_alpha': 8.562366838108819, 'reg_lambda': 5.9750084776427155, 'subsample': 0.702928153862698}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:30:22,998] Trial 22 finished with value: 0.6620498471510156 and parameters: {'n_estimators': 2624, 'learning_rate': 0.006330325536802126, 'num_leaves': 36, 'max_depth': 4, 'reg_alpha': 8.548496983973978, 'reg_lambda': 6.496195791126347, 'subsample': 0.6272300763511351}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:32:18,134] Trial 23 finished with value: 0.6645404495990304 and parameters: {'n_estimators': 2201, 'learning_rate': 0.0038705564476984033, 'num_leaves': 31, 'max_depth': 5, 'reg_alpha': 6.548021686307408, 'reg_lambda': 4.66949683265263, 'subsample': 0.6874859476786327}. Best is trial 17 with value: 0.6661263989037243.\n",
            "[I 2025-04-25 01:34:02,037] Trial 24 finished with value: 0.6668745502161567 and parameters: {'n_estimators': 1725, 'learning_rate': 0.012080707616124267, 'num_leaves': 26, 'max_depth': 6, 'reg_alpha': 7.998233394497391, 'reg_lambda': 7.78695508628189, 'subsample': 0.7804377627241247}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:35:41,113] Trial 25 finished with value: 0.6564846519674641 and parameters: {'n_estimators': 1666, 'learning_rate': 0.03138612940640835, 'num_leaves': 26, 'max_depth': 6, 'reg_alpha': 5.457658215990275, 'reg_lambda': 9.926806774703671, 'subsample': 0.7805458829845242}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:36:58,634] Trial 26 finished with value: 0.6623251750203356 and parameters: {'n_estimators': 1185, 'learning_rate': 0.01332633833261725, 'num_leaves': 25, 'max_depth': 7, 'reg_alpha': 7.959607154117326, 'reg_lambda': 8.303821109995793, 'subsample': 0.8011994631821042}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:38:29,089] Trial 27 finished with value: 0.6664254950816191 and parameters: {'n_estimators': 1386, 'learning_rate': 0.00806618711409904, 'num_leaves': 36, 'max_depth': 6, 'reg_alpha': 6.428172043286654, 'reg_lambda': 1.8001198363391877, 'subsample': 0.7319069984982102}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:40:08,540] Trial 28 finished with value: 0.665257855604285 and parameters: {'n_estimators': 1338, 'learning_rate': 0.007723297216067839, 'num_leaves': 40, 'max_depth': 7, 'reg_alpha': 6.865056847215454, 'reg_lambda': 2.057935516064646, 'subsample': 0.7286919105040611}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:42:44,460] Trial 29 finished with value: 0.6562738225741193 and parameters: {'n_estimators': 1985, 'learning_rate': 0.013616852428851542, 'num_leaves': 45, 'max_depth': 8, 'reg_alpha': 5.916910390599076, 'reg_lambda': 2.0530774182799645, 'subsample': 0.7557837260410755}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:44:06,573] Trial 30 finished with value: 0.6641133952667546 and parameters: {'n_estimators': 1557, 'learning_rate': 0.019135492607984254, 'num_leaves': 21, 'max_depth': 6, 'reg_alpha': 4.328211415078615, 'reg_lambda': 3.467161567739687, 'subsample': 0.7679447990812401}. Best is trial 24 with value: 0.6668745502161567.\n",
            "[I 2025-04-25 01:45:30,595] Trial 31 finished with value: 0.6672850458050812 and parameters: {'n_estimators': 1271, 'learning_rate': 0.012706418098548994, 'num_leaves': 37, 'max_depth': 6, 'reg_alpha': 6.99861798660386, 'reg_lambda': 5.354252163858646, 'subsample': 0.7255583687042467}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:47:07,889] Trial 32 finished with value: 0.66217796034981 and parameters: {'n_estimators': 1321, 'learning_rate': 0.01692947148620078, 'num_leaves': 38, 'max_depth': 7, 'reg_alpha': 6.888896233681378, 'reg_lambda': 1.4734453987794063, 'subsample': 0.7251159974214552}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:49:06,429] Trial 33 finished with value: 0.6661942618434706 and parameters: {'n_estimators': 1844, 'learning_rate': 0.011188001272163206, 'num_leaves': 41, 'max_depth': 6, 'reg_alpha': 4.943682267488506, 'reg_lambda': 3.853353766380014, 'subsample': 0.8074783949556852}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:50:40,388] Trial 34 finished with value: 0.6621493856644198 and parameters: {'n_estimators': 1816, 'learning_rate': 0.012511016737502404, 'num_leaves': 42, 'max_depth': 5, 'reg_alpha': 4.753439108059606, 'reg_lambda': 3.8884409942883567, 'subsample': 0.8075935568772468}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:51:46,544] Trial 35 finished with value: 0.6654293347255081 and parameters: {'n_estimators': 1003, 'learning_rate': 0.024001375833076488, 'num_leaves': 41, 'max_depth': 6, 'reg_alpha': 3.3324715891983936, 'reg_lambda': 7.512744922593778, 'subsample': 0.8520767377969393}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:53:29,077] Trial 36 finished with value: 0.6669434364490314 and parameters: {'n_estimators': 1582, 'learning_rate': 0.009671551894154157, 'num_leaves': 45, 'max_depth': 6, 'reg_alpha': 5.702774046320887, 'reg_lambda': 8.920544363424995, 'subsample': 0.8167554908437962}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:54:56,503] Trial 37 finished with value: 0.6486300244622875 and parameters: {'n_estimators': 1505, 'learning_rate': 0.04287820852909931, 'num_leaves': 46, 'max_depth': 5, 'reg_alpha': 9.022574905706742, 'reg_lambda': 8.804415968817965, 'subsample': 0.8637462069187962}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:56:16,813] Trial 38 finished with value: 0.6614600892113152 and parameters: {'n_estimators': 1241, 'learning_rate': 0.008951701002153064, 'num_leaves': 25, 'max_depth': 7, 'reg_alpha': 5.687139442942618, 'reg_lambda': 8.950934147886946, 'subsample': 0.7681711540713065}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:58:32,188] Trial 39 finished with value: 0.6561842534164967 and parameters: {'n_estimators': 1670, 'learning_rate': 0.02112997232004344, 'num_leaves': 48, 'max_depth': 7, 'reg_alpha': 7.996410855105218, 'reg_lambda': 8.07421625531775, 'subsample': 0.818406556476209}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 01:59:33,938] Trial 40 finished with value: 0.6649576276021725 and parameters: {'n_estimators': 1425, 'learning_rate': 0.015594816681973742, 'num_leaves': 44, 'max_depth': 4, 'reg_alpha': 7.188452432070129, 'reg_lambda': 9.339792259020994, 'subsample': 0.8468611620382852}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 02:01:36,800] Trial 41 finished with value: 0.6638776812450589 and parameters: {'n_estimators': 1972, 'learning_rate': 0.011477059193557106, 'num_leaves': 36, 'max_depth': 6, 'reg_alpha': 4.683262355741836, 'reg_lambda': 5.638542482249148, 'subsample': 0.8006962242472255}. Best is trial 31 with value: 0.6672850458050812.\n",
            "[I 2025-04-25 02:03:21,767] Trial 42 finished with value: 0.6679285731473494 and parameters: {'n_estimators': 1633, 'learning_rate': 0.008179131121895214, 'num_leaves': 42, 'max_depth': 6, 'reg_alpha': 5.075970499480513, 'reg_lambda': 4.106798226483678, 'subsample': 0.8208669653381765}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:05:08,971] Trial 43 finished with value: 0.6661182280631381 and parameters: {'n_estimators': 1669, 'learning_rate': 0.009582498765232336, 'num_leaves': 50, 'max_depth': 6, 'reg_alpha': 3.687016018453705, 'reg_lambda': 7.358935058334063, 'subsample': 0.8286975790757953}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:06:14,198] Trial 44 finished with value: 0.661897950139205 and parameters: {'n_estimators': 1149, 'learning_rate': 0.007089557445241971, 'num_leaves': 45, 'max_depth': 5, 'reg_alpha': 6.680203546972415, 'reg_lambda': 8.481598472362924, 'subsample': 0.8783933642612688}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:07:43,884] Trial 45 finished with value: 0.6608589355072296 and parameters: {'n_estimators': 1569, 'learning_rate': 0.008127226084473537, 'num_leaves': 48, 'max_depth': 6, 'reg_alpha': 0.3429087821818282, 'reg_lambda': 5.150523303199429, 'subsample': 0.7634510522959977}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:09:02,820] Trial 46 finished with value: 0.6580163357274671 and parameters: {'n_estimators': 1374, 'learning_rate': 0.003186868908747404, 'num_leaves': 39, 'max_depth': 5, 'reg_alpha': 5.485598404457543, 'reg_lambda': 9.280506884904511, 'subsample': 0.7890469450183586}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:10:45,856] Trial 47 finished with value: 0.6361349641772983 and parameters: {'n_estimators': 2182, 'learning_rate': 0.08031641834610379, 'num_leaves': 31, 'max_depth': 6, 'reg_alpha': 7.312793932648119, 'reg_lambda': 7.882199526342073, 'subsample': 0.7359865033064276}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:12:10,729] Trial 48 finished with value: 0.6614749734750018 and parameters: {'n_estimators': 1254, 'learning_rate': 0.014625700022740988, 'num_leaves': 35, 'max_depth': 7, 'reg_alpha': 2.568490037956599, 'reg_lambda': 9.99025022003007, 'subsample': 0.8303331731721564}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:13:56,911] Trial 49 finished with value: 0.662366385825418 and parameters: {'n_estimators': 1989, 'learning_rate': 0.0049655052065072265, 'num_leaves': 27, 'max_depth': 5, 'reg_alpha': 8.025276981203701, 'reg_lambda': 6.889531633951806, 'subsample': 0.8165208811456673}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:15:36,620] Trial 50 finished with value: 0.6660290155076662 and parameters: {'n_estimators': 1459, 'learning_rate': 0.0102835954044231, 'num_leaves': 43, 'max_depth': 6, 'reg_alpha': 9.217107662511383, 'reg_lambda': 5.695162155747594, 'subsample': 0.6698175050506353}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:17:26,839] Trial 51 finished with value: 0.6653971009919618 and parameters: {'n_estimators': 1735, 'learning_rate': 0.011260590726862927, 'num_leaves': 40, 'max_depth': 6, 'reg_alpha': 4.855667669801623, 'reg_lambda': 4.055270790567672, 'subsample': 0.7869762081694791}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:19:27,754] Trial 52 finished with value: 0.667788288962103 and parameters: {'n_estimators': 1879, 'learning_rate': 0.008785752705187552, 'num_leaves': 42, 'max_depth': 6, 'reg_alpha': 5.2301810554863195, 'reg_lambda': 3.541414352776025, 'subsample': 0.8026676864885608}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:21:13,056] Trial 53 finished with value: 0.6669537469025227 and parameters: {'n_estimators': 1592, 'learning_rate': 0.00833522891162436, 'num_leaves': 46, 'max_depth': 6, 'reg_alpha': 5.946911463107397, 'reg_lambda': 4.53801113408548, 'subsample': 0.8449572844987085}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:22:58,785] Trial 54 finished with value: 0.6581567284438031 and parameters: {'n_estimators': 1563, 'learning_rate': 0.01758466991891207, 'num_leaves': 47, 'max_depth': 6, 'reg_alpha': 5.874190547557298, 'reg_lambda': 4.539716875290782, 'subsample': 0.8384369781668422}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:25:18,283] Trial 55 finished with value: 0.6641571022868926 and parameters: {'n_estimators': 1912, 'learning_rate': 0.006661455706647731, 'num_leaves': 44, 'max_depth': 7, 'reg_alpha': 5.141491445898673, 'reg_lambda': 3.4262534741103883, 'subsample': 0.8686104402221055}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:27:29,917] Trial 56 finished with value: 0.6663422982493873 and parameters: {'n_estimators': 2049, 'learning_rate': 0.003858039089606904, 'num_leaves': 42, 'max_depth': 6, 'reg_alpha': 4.0111561023808475, 'reg_lambda': 4.833260761836771, 'subsample': 0.8465426851851693}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:29:28,771] Trial 57 finished with value: 0.667804971740985 and parameters: {'n_estimators': 2295, 'learning_rate': 0.008748184836628318, 'num_leaves': 46, 'max_depth': 5, 'reg_alpha': 6.117683353649964, 'reg_lambda': 2.5167921136280595, 'subsample': 0.8197099115345221}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:31:27,753] Trial 58 finished with value: 0.6654225437802013 and parameters: {'n_estimators': 2311, 'learning_rate': 0.005584455044910437, 'num_leaves': 46, 'max_depth': 5, 'reg_alpha': 6.107163709015937, 'reg_lambda': 2.722869658553381, 'subsample': 0.8221201694730094}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:33:09,549] Trial 59 finished with value: 0.6637427150831918 and parameters: {'n_estimators': 2559, 'learning_rate': 0.00874683559147907, 'num_leaves': 49, 'max_depth': 4, 'reg_alpha': 5.2783416887417305, 'reg_lambda': 4.28949943254782, 'subsample': 0.8788392852917017}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:34:13,761] Trial 60 finished with value: 0.6518611500375951 and parameters: {'n_estimators': 1089, 'learning_rate': 0.0027140578247254565, 'num_leaves': 46, 'max_depth': 5, 'reg_alpha': 4.5258249037715625, 'reg_lambda': 2.581060780359778, 'subsample': 0.8972853309602117}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:36:10,801] Trial 61 finished with value: 0.6596833577559293 and parameters: {'n_estimators': 1734, 'learning_rate': 0.012876410010657051, 'num_leaves': 44, 'max_depth': 6, 'reg_alpha': 7.591569927816238, 'reg_lambda': 3.475932624973367, 'subsample': 0.7969380047010703}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:38:39,849] Trial 62 finished with value: 0.6646167314504243 and parameters: {'n_estimators': 2286, 'learning_rate': 0.0074721152696288345, 'num_leaves': 48, 'max_depth': 6, 'reg_alpha': 5.662616339527913, 'reg_lambda': 3.1103639570659016, 'subsample': 0.810743947765504}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:40:07,559] Trial 63 finished with value: 0.6652832983925243 and parameters: {'n_estimators': 1644, 'learning_rate': 0.00624410128954681, 'num_leaves': 42, 'max_depth': 5, 'reg_alpha': 6.284051716385429, 'reg_lambda': 4.934238945506008, 'subsample': 0.8387982823193175}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:42:24,844] Trial 64 finished with value: 0.6629023898669917 and parameters: {'n_estimators': 2070, 'learning_rate': 0.009844998629814406, 'num_leaves': 45, 'max_depth': 6, 'reg_alpha': 6.868547256426171, 'reg_lambda': 2.5538557269031488, 'subsample': 0.7757001923757246}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:43:25,482] Trial 65 finished with value: 0.6554456838488126 and parameters: {'n_estimators': 1803, 'learning_rate': 0.015053863888472279, 'num_leaves': 47, 'max_depth': 3, 'reg_alpha': 5.099658372973157, 'reg_lambda': 5.36632806654619, 'subsample': 0.8255686640957298}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:45:14,329] Trial 66 finished with value: 0.663329878323625 and parameters: {'n_estimators': 1889, 'learning_rate': 0.01199933988950046, 'num_leaves': 23, 'max_depth': 6, 'reg_alpha': 8.324777978263771, 'reg_lambda': 6.108797368713935, 'subsample': 0.8547438526201803}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:47:40,764] Trial 67 finished with value: 0.6661695942772983 and parameters: {'n_estimators': 2901, 'learning_rate': 0.004700572807993237, 'num_leaves': 43, 'max_depth': 5, 'reg_alpha': 6.017314025047894, 'reg_lambda': 4.286384024740295, 'subsample': 0.7950558795271715}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:50:44,851] Trial 68 finished with value: 0.6436216402805883 and parameters: {'n_estimators': 2735, 'learning_rate': 0.02066677284350757, 'num_leaves': 37, 'max_depth': 6, 'reg_alpha': 6.524635734423272, 'reg_lambda': 1.2930718646681902, 'subsample': 0.8359906919766896}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:52:31,909] Trial 69 finished with value: 0.6634520223125034 and parameters: {'n_estimators': 1484, 'learning_rate': 0.008063180000723461, 'num_leaves': 39, 'max_depth': 7, 'reg_alpha': 5.538675103428124, 'reg_lambda': 3.5954118752407984, 'subsample': 0.7540104422926871}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:53:56,189] Trial 70 finished with value: 0.6654566380467083 and parameters: {'n_estimators': 1251, 'learning_rate': 0.01063864715079958, 'num_leaves': 41, 'max_depth': 6, 'reg_alpha': 7.0435836561712115, 'reg_lambda': 6.71896857786727, 'subsample': 0.8117846025499601}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:55:22,403] Trial 71 finished with value: 0.6675984990956569 and parameters: {'n_estimators': 1327, 'learning_rate': 0.008844154640560365, 'num_leaves': 34, 'max_depth': 6, 'reg_alpha': 6.4955009780974, 'reg_lambda': 1.7809373627650855, 'subsample': 0.7443257295611457}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:57:00,596] Trial 72 finished with value: 0.6669583362171594 and parameters: {'n_estimators': 1607, 'learning_rate': 0.009305440336148831, 'num_leaves': 29, 'max_depth': 6, 'reg_alpha': 5.847296853802849, 'reg_lambda': 2.2280007677710745, 'subsample': 0.7190519742957862}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 02:58:37,189] Trial 73 finished with value: 0.6653023688553727 and parameters: {'n_estimators': 1582, 'learning_rate': 0.008915433042860523, 'num_leaves': 30, 'max_depth': 6, 'reg_alpha': 5.707922766728518, 'reg_lambda': 2.355886382799166, 'subsample': 0.7121413734551209}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 03:00:02,112] Trial 74 finished with value: 0.6653453161578854 and parameters: {'n_estimators': 1317, 'learning_rate': 0.0067880155531218345, 'num_leaves': 33, 'max_depth': 6, 'reg_alpha': 6.139594580162865, 'reg_lambda': 0.8529288259375851, 'subsample': 0.6937423257393401}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 03:01:17,223] Trial 75 finished with value: 0.6660120846577228 and parameters: {'n_estimators': 1120, 'learning_rate': 0.007460107458051149, 'num_leaves': 34, 'max_depth': 6, 'reg_alpha': 6.6090198498146755, 'reg_lambda': 1.5312096962302477, 'subsample': 0.7439983177800463}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 03:02:34,086] Trial 76 finished with value: 0.6625031039891564 and parameters: {'n_estimators': 1421, 'learning_rate': 0.005601382301492843, 'num_leaves': 49, 'max_depth': 5, 'reg_alpha': 4.347597268638804, 'reg_lambda': 2.9819988436510356, 'subsample': 0.7219781733233731}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 03:04:14,116] Trial 77 finished with value: 0.6641281244860278 and parameters: {'n_estimators': 1620, 'learning_rate': 0.009023649080089692, 'num_leaves': 28, 'max_depth': 7, 'reg_alpha': 5.26956868118655, 'reg_lambda': 0.2921547068864383, 'subsample': 0.7374419983930581}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 03:05:56,617] Trial 78 finished with value: 0.66475318603866 and parameters: {'n_estimators': 1509, 'learning_rate': 0.004073680699742441, 'num_leaves': 45, 'max_depth': 6, 'reg_alpha': 5.889364628903636, 'reg_lambda': 2.1240522957204884, 'subsample': 0.6973850768642752}. Best is trial 42 with value: 0.6679285731473494.\n",
            "[I 2025-04-25 03:09:55,880] Trial 79 finished with value: 0.6488528387887881 and parameters: {'n_estimators': 3051, 'learning_rate': 0.013427878657052195, 'num_leaves': 47, 'max_depth': 7, 'reg_alpha': 7.413475390076197, 'reg_lambda': 3.752818505380932, 'subsample': 0.6780596125254209}. Best is trial 42 with value: 0.6679285731473494.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 1633, 'learning_rate': 0.008179131121895214, 'num_leaves': 42, 'max_depth': 6, 'reg_alpha': 5.075970499480513, 'reg_lambda': 4.106798226483678, 'subsample': 0.8208669653381765}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 1000, 4000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 10),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
        "    }\n",
        "    model = LGBMClassifier(**params, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    return roc_auc_score(y_test, y_proba)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=80)\n",
        "print(study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b25a59d8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 1633,\n",
              " 'learning_rate': 0.008179131121895214,\n",
              " 'num_leaves': 42,\n",
              " 'max_depth': 6,\n",
              " 'reg_alpha': 5.075970499480513,\n",
              " 'reg_lambda': 4.106798226483678,\n",
              " 'subsample': 0.8208669653381765}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params = study.best_params\n",
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b70aee8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc_auc is 0.6734\n"
          ]
        }
      ],
      "source": [
        "model = LGBMClassifier(\n",
        "    **best_params,\n",
        "    boosting_type='goss',\n",
        "    objective='binary',            # Для бинарной классификации\n",
        "    metric='auc',                  # Оптимизация ROC-AUC\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "print(f\"roc_auc is {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8829ec8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_true_test_df = pd.read_csv('./datasets/test/test.csv')\n",
        "X_true_test = X_true_test_df.drop(columns=['index'])\n",
        "indexes = X_true_test_df['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b301ab21",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>194357</td>\n",
              "      <td>0.006393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>313222</td>\n",
              "      <td>0.017928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>321873</td>\n",
              "      <td>0.032909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118689</td>\n",
              "      <td>0.022984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>342561</td>\n",
              "      <td>0.006270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106269</th>\n",
              "      <td>239350</td>\n",
              "      <td>0.026953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106270</th>\n",
              "      <td>324235</td>\n",
              "      <td>0.012679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106271</th>\n",
              "      <td>108007</td>\n",
              "      <td>0.002852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106272</th>\n",
              "      <td>236241</td>\n",
              "      <td>0.022973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106273</th>\n",
              "      <td>185650</td>\n",
              "      <td>0.007523</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106274 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index         0\n",
              "0       194357  0.006393\n",
              "1       313222  0.017928\n",
              "2       321873  0.032909\n",
              "3       118689  0.022984\n",
              "4       342561  0.006270\n",
              "...        ...       ...\n",
              "106269  239350  0.026953\n",
              "106270  324235  0.012679\n",
              "106271  108007  0.002852\n",
              "106272  236241  0.022973\n",
              "106273  185650  0.007523\n",
              "\n",
              "[106274 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true_pred = model.predict_proba(X_true_test)[:, 1]\n",
        "output = pd.concat([indexes, pd.Series(y_true_pred)], axis=1)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "acc54488",
      "metadata": {},
      "outputs": [],
      "source": [
        "output.to_csv(\"output3.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "2e9111be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# для проверки другого lightgbmclassifier\n",
        "output.to_csv(\"output3_2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "444a88a2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
